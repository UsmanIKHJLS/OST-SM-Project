# Base image
FROM codercom/code-server:latest

# Root user for installing packages
USER root

# Install basic dependencies
RUN apt-get update && apt-get install -y \
    wget \
    bzip2 \
    build-essential \
    openjdk-11-jdk && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Configure Java environment variables (required for Spark)
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH=$JAVA_HOME/bin:$PATH

# Download and install Miniconda
ENV CONDA_DIR /opt/conda
RUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh && \
    bash /tmp/miniconda.sh -b -p $CONDA_DIR && \
    rm /tmp/miniconda.sh && \
    $CONDA_DIR/bin/conda clean --all -y

# Add Conda to PATH
ENV PATH=$CONDA_DIR/bin:$PATH

# Update Conda and create default environment
RUN conda update -n base -c defaults conda && \
    conda create -n venv python=3.8 -y && \
    conda clean --all -y

# Install Jupyter, PySpark and ipykernel in the base environment
RUN conda install -n base -c conda-forge \
    notebook \
    ipykernel \
    pyspark && \
    python -m ipykernel install --user --name=base --display-name "Python (base)"

# Install additional libraries in the Conda environment
RUN conda run -n venv pip install \
        numpy \
        pandas \
        matplotlib \
        scikit-learn \
        seaborn \
        statsmodels \
        notebook \
        ipykernel && \
    conda run -n venv python -m ipykernel install --user --name=venv --display-name "Python (Conda venv)"

# Configure environment variable for executing .ipynb files
ENV JUPYTER_ENABLE_LAB=yes

# Return to standard user
USER coder
