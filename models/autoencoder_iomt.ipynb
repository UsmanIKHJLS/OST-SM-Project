{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the historical data\n",
    "data = pd.read_csv(\"../Datasets/IoMT_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features\n",
    "numerical_features = [\"SrcBytes\", \"DstBytes\", \"SrcLoad\", \"DstLoad\", \"Temp\", \"SpO2\", \n",
    "                      \"Pulse_Rate\", \"SYS\", \"DIA\", \"Heart_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data: remove missing values and normalize\n",
    "data = data[numerical_features].dropna()\n",
    "data = (data - data.mean()) / data.std()  # Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - loss: 1.6766 - val_loss: 0.3417\n",
      "Epoch 2/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 1.1707 - val_loss: 0.3348\n",
      "Epoch 3/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.7789 - val_loss: 0.3200\n",
      "Epoch 4/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 0.8051 - val_loss: 0.2897\n",
      "Epoch 5/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.7223 - val_loss: 0.2537\n",
      "Epoch 6/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.6487 - val_loss: 0.2203\n",
      "Epoch 7/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.5049 - val_loss: 0.1932\n",
      "Epoch 8/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.5083 - val_loss: 0.1779\n",
      "Epoch 9/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 0.5250 - val_loss: 0.1689\n",
      "Epoch 10/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.5399 - val_loss: 0.1605\n",
      "Epoch 11/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.4133 - val_loss: 0.1611\n",
      "Epoch 12/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.4833 - val_loss: 0.1524\n",
      "Epoch 13/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.4163 - val_loss: 0.1466\n",
      "Epoch 14/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.3009 - val_loss: 0.1532\n",
      "Epoch 15/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.2904 - val_loss: 0.1448\n",
      "Epoch 16/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.2777 - val_loss: 0.1458\n",
      "Epoch 17/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.3118 - val_loss: 0.1423\n",
      "Epoch 18/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 0.3080 - val_loss: 0.1369\n",
      "Epoch 19/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.3165 - val_loss: 0.1374\n",
      "Epoch 20/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 0.3708 - val_loss: 0.1351\n",
      "Epoch 21/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.2749 - val_loss: 0.1344\n",
      "Epoch 22/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 0.3008 - val_loss: 0.1339\n",
      "Epoch 23/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.3019 - val_loss: 0.1357\n",
      "Epoch 24/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.2876 - val_loss: 0.1356\n",
      "Epoch 25/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.2692 - val_loss: 0.1393\n",
      "Epoch 26/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - loss: 0.3438 - val_loss: 0.1348\n",
      "Epoch 27/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 0.2722 - val_loss: 0.1384\n",
      "Epoch 28/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.3562 - val_loss: 0.1360\n",
      "Epoch 29/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.2793 - val_loss: 0.1413\n",
      "Epoch 30/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.2576 - val_loss: 0.1302\n",
      "Epoch 31/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.2708 - val_loss: 0.1287\n",
      "Epoch 32/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.2920 - val_loss: 0.1374\n",
      "Epoch 33/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.3343 - val_loss: 0.1420\n",
      "Epoch 34/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 0.2402 - val_loss: 0.1403\n",
      "Epoch 35/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.2909 - val_loss: 0.1395\n",
      "Epoch 36/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.2430 - val_loss: 0.1441\n",
      "Epoch 37/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.3032 - val_loss: 0.1467\n",
      "Epoch 38/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.2907 - val_loss: 0.1398\n",
      "Epoch 39/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 0.2738 - val_loss: 0.1438\n",
      "Epoch 40/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.2920 - val_loss: 0.1412\n",
      "Epoch 41/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 0.3263 - val_loss: 0.1420\n",
      "Epoch 42/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.2680 - val_loss: 0.1388\n",
      "Epoch 43/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.2240 - val_loss: 0.1384\n",
      "Epoch 44/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.2498 - val_loss: 0.1377\n",
      "Epoch 45/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.2624 - val_loss: 0.1437\n",
      "Epoch 46/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.2952 - val_loss: 0.1431\n",
      "Epoch 47/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.2525 - val_loss: 0.1433\n",
      "Epoch 48/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.4393 - val_loss: 0.1412\n",
      "Epoch 49/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.2518 - val_loss: 0.1442\n",
      "Epoch 50/50\n",
      "\u001b[1m408/408\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.2513 - val_loss: 0.1400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a1eec3b3d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "X = data.to_numpy()\n",
    "\n",
    "# Build the autoencoder model\n",
    "input_dim = X.shape[1]\n",
    "encoding_dim = 5  # Size of the encoded representation\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoded = Dense(input_dim, activation='linear')(encoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "autoencoder.fit(X, X, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: anomaly_detection_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: anomaly_detection_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'anomaly_detection_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2894517533008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2894518829824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2894518832464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2894518833344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "# Save the model for use in Spark\n",
    "autoencoder.export(\"anomaly_detection_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
